{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2 Limor Nunu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f2ce44f582049beb64199c67365ea4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b404a71d95f47958c70cd23d74e8d5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d44a3d67b6a4c3bb15a8d866990a5fc",
              "IPY_MODEL_b7e69874a0f64bf4af3cb127cf5762d8"
            ]
          }
        },
        "6b404a71d95f47958c70cd23d74e8d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d44a3d67b6a4c3bb15a8d866990a5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e13eb3c98e0c4ecbb5ec5f0768bd457d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c98571b9fa764b228bff69d30b08a3da"
          }
        },
        "b7e69874a0f64bf4af3cb127cf5762d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_93b41b0c1aaf4d4abbea8ceedbf7f9b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5069f21dfb47443a827caf42bdfb1fc2"
          }
        },
        "e13eb3c98e0c4ecbb5ec5f0768bd457d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c98571b9fa764b228bff69d30b08a3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93b41b0c1aaf4d4abbea8ceedbf7f9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5069f21dfb47443a827caf42bdfb1fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b58b4773a0424e89affac7996910961d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8ded735256f44219e6978d68828fefa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90432e05d43e4acbbff4d97262f4bb8b",
              "IPY_MODEL_36237e05a707434b8793a2508a5262de"
            ]
          }
        },
        "c8ded735256f44219e6978d68828fefa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90432e05d43e4acbbff4d97262f4bb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62551e9551e747f4b82c8b6ad7578792",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f83b8acb05e4031adfd29dcf8d06379"
          }
        },
        "36237e05a707434b8793a2508a5262de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30a5a09c8f434e0d928b79dee8b87371",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.34MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d64682b44d84fb682e5ae7a946805cc"
          }
        },
        "62551e9551e747f4b82c8b6ad7578792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f83b8acb05e4031adfd29dcf8d06379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a5a09c8f434e0d928b79dee8b87371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d64682b44d84fb682e5ae7a946805cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5SebrLhyTvP"
      },
      "source": [
        "# GPT2 Exercise - Limor Nunu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMU_XLIjydSq"
      },
      "source": [
        "###**Imports and Installations:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1t_9mkD8qh5",
        "outputId": "63e5704b-74ad-4070-ec6d-f6668b122a21"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 17.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=2034a107ebc64d82019fbd5a798ae0852508cd1a6b7a8756c251db597b34aee7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_QmvKiW7ca7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from transformers import pipeline\r\n",
        "import tensorflow as tf\r\n",
        "from transformers import GPT2Tokenizer, GPT2Config, TFGPT2LMHeadModel\r\n",
        "import pandas as pd\r\n",
        "import regex as re\r\n",
        "import math\r\n",
        "import ast"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD5ox1AaWSmB"
      },
      "source": [
        "Cloning the HuggingFace repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwsVsBbGXKBW",
        "outputId": "585e68f0-4386-4b0e-f2cb-1ebc317946b0"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 63607 (delta 11), reused 21 (delta 0), pack-reused 63562\u001b[K\n",
            "Receiving objects: 100% (63607/63607), 48.29 MiB | 29.14 MiB/s, done.\n",
            "Resolving deltas: 100% (45054/45054), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0df-FVM5yhQm"
      },
      "source": [
        "### **Loading the data and cleaning it:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMdrVZbQozyw"
      },
      "source": [
        "df = pd.read_csv('fake_news_df.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuXuPm33B078",
        "outputId": "ab17d655-5acf-441c-e8dc-a97ca3203df3"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Article Number', 'URL of article', 'Fake or Satire?',\n",
              "       'URL of rebutting article', 'Fake or Satire?.1', 'content_1',\n",
              "       'content_2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZMRqh96_-Yr"
      },
      "source": [
        "The content columns are columns that I scrape using the \"article_extractor.py\" program I wrote."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM-FBQ7FyvLo"
      },
      "source": [
        "Converting the \"content\" columns into lists:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0zXvlMAxM14"
      },
      "source": [
        "df.content_1 = [ast.literal_eval(i) for i in df.content_1]\r\n",
        "df.content_2 = [ast.literal_eval(i) for i in df.content_2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZmxxhXeAkJm"
      },
      "source": [
        "The lists made of elements with the content (not all the content comes as one piece)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEZlHKRDvtKZ"
      },
      "source": [
        "Joining the lists into a long string of the content:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55pGbBF62o7S"
      },
      "source": [
        "df['joined_content_1'] = [\" \".join(i).strip() for i in df.content_1]\r\n",
        "df['joined_content_2'] = [\" \".join(i).strip() for i in df.content_2]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFgKqurzv7do"
      },
      "source": [
        "Calculating the length of the strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEHdBVw99DLK"
      },
      "source": [
        "df['len_content_1'] = [len(i) for i in df.joined_content_1]\r\n",
        "df['len_content_2'] = [len(i) for i in df.joined_content_2]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MDHTKNpwBYI"
      },
      "source": [
        "Finding the maximum length between the two columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNEVHrDmG--y"
      },
      "source": [
        "df['max_len'] = df[['len_content_1', 'len_content_2']].max(axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hldHCCQazwLR"
      },
      "source": [
        "Looking at the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "L01_PDWtxtnJ",
        "outputId": "1876461a-0389-4c41-9ccf-4f2cf0b4db94"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Number</th>\n",
              "      <th>URL of article</th>\n",
              "      <th>Fake or Satire?</th>\n",
              "      <th>URL of rebutting article</th>\n",
              "      <th>Fake or Satire?.1</th>\n",
              "      <th>content_1</th>\n",
              "      <th>content_2</th>\n",
              "      <th>joined_content_1</th>\n",
              "      <th>joined_content_2</th>\n",
              "      <th>len_content_1</th>\n",
              "      <th>len_content_2</th>\n",
              "      <th>max_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>375.0</td>\n",
              "      <td>http://www.redflagnews.com/headlines-2016/cdc-...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/cdc-forced-vaccinations/</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[\\n      Please switch to a supported browser ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Please switch to a supported browser to contin...</td>\n",
              "      <td></td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>376.0</td>\n",
              "      <td>http://www.redflagnews.com/headlines-2016/-out...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/white-house-logo-change/</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[\\n      Please switch to a supported browser ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Please switch to a supported browser to contin...</td>\n",
              "      <td></td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>377.0</td>\n",
              "      <td>http://www.redflagnews.com/headlines-2016/whit...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/obama-veterans-money-to-...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[\\n      Please switch to a supported browser ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Please switch to a supported browser to contin...</td>\n",
              "      <td></td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>378.0</td>\n",
              "      <td>http://www.redflagnews.com/headlines-2016/obam...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/obama-veterans-money-to-...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[\\n      Please switch to a supported browser ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Please switch to a supported browser to contin...</td>\n",
              "      <td></td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>379.0</td>\n",
              "      <td>http://www.redflagnews.com/headlines-2016/cali...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/california-to-jail-clima...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[\\n      Please switch to a supported browser ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Please switch to a supported browser to contin...</td>\n",
              "      <td></td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Article Number  ... max_len\n",
              "0           375.0  ...     237\n",
              "1           376.0  ...     237\n",
              "2           377.0  ...     237\n",
              "3           378.0  ...     237\n",
              "4           379.0  ...     237\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "H2TgHhCLzBkX",
        "outputId": "27cde1ec-2675-4032-b5c6-1b99801f37e6"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Number</th>\n",
              "      <th>len_content_1</th>\n",
              "      <th>len_content_2</th>\n",
              "      <th>max_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>262.841924</td>\n",
              "      <td>1203.797251</td>\n",
              "      <td>64.560137</td>\n",
              "      <td>1213.865979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>166.078219</td>\n",
              "      <td>3225.583054</td>\n",
              "      <td>375.413288</td>\n",
              "      <td>3228.229278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>109.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>250.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>395.500000</td>\n",
              "      <td>776.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>776.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>587.000000</td>\n",
              "      <td>34310.000000</td>\n",
              "      <td>3519.000000</td>\n",
              "      <td>34310.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Article Number  len_content_1  len_content_2       max_len\n",
              "count      291.000000     291.000000     291.000000    291.000000\n",
              "mean       262.841924    1203.797251      64.560137   1213.865979\n",
              "std        166.078219    3225.583054     375.413288   3228.229278\n",
              "min          8.000000       0.000000       0.000000      0.000000\n",
              "25%        109.500000       0.000000       0.000000      0.000000\n",
              "50%        250.000000      12.000000       0.000000     12.000000\n",
              "75%        395.500000     776.000000       0.000000    776.000000\n",
              "max        587.000000   34310.000000    3519.000000  34310.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Za6ugRZz4Or"
      },
      "source": [
        "We can see that 75% of the rows is content with length less than 776.\r\n",
        "\r\n",
        "Probably not relevant content.\r\n",
        "\r\n",
        "Let's check this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "mKn9fbgwxzBZ",
        "outputId": "ca0684c6-edf2-4ee2-914d-2ad72842f886"
      },
      "source": [
        "df[df.max_len == 776].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Number</th>\n",
              "      <th>URL of article</th>\n",
              "      <th>Fake or Satire?</th>\n",
              "      <th>URL of rebutting article</th>\n",
              "      <th>Fake or Satire?.1</th>\n",
              "      <th>content_1</th>\n",
              "      <th>content_2</th>\n",
              "      <th>joined_content_1</th>\n",
              "      <th>joined_content_2</th>\n",
              "      <th>len_content_1</th>\n",
              "      <th>len_content_2</th>\n",
              "      <th>max_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>43.0</td>\n",
              "      <td>http://yournewswire.com/cia-hitler-argentina-ww2/</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/fbi-files-prove-adolf-hi...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[It seems we can’t find what you’re looking fo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>It seems we can’t find what you’re looking for...</td>\n",
              "      <td></td>\n",
              "      <td>776</td>\n",
              "      <td>0</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>44.0</td>\n",
              "      <td>http://yournewswire.com/planned-parenthood-ext...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.politifact.com/new-hampshire/statem...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[It seems we can’t find what you’re looking fo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>It seems we can’t find what you’re looking for...</td>\n",
              "      <td></td>\n",
              "      <td>776</td>\n",
              "      <td>0</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>45.0</td>\n",
              "      <td>http://yournewswire.com/charlottesville-hillar...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/charlottesville-killer-r...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[It seems we can’t find what you’re looking fo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>It seems we can’t find what you’re looking for...</td>\n",
              "      <td></td>\n",
              "      <td>776</td>\n",
              "      <td>0</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>46.0</td>\n",
              "      <td>http://yournewswire.com/fbi-seth-rich-dnc/</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/seth-rich-dnc-wikileaks-...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[It seems we can’t find what you’re looking fo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>It seems we can’t find what you’re looking for...</td>\n",
              "      <td></td>\n",
              "      <td>776</td>\n",
              "      <td>0</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>47.0</td>\n",
              "      <td>http://yournewswire.com/mit-global-warming-dat...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/climatology-fraud-global...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[It seems we can’t find what you’re looking fo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>It seems we can’t find what you’re looking for...</td>\n",
              "      <td></td>\n",
              "      <td>776</td>\n",
              "      <td>0</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Article Number  ... max_len\n",
              "27            43.0  ...     776\n",
              "28            44.0  ...     776\n",
              "29            45.0  ...     776\n",
              "30            46.0  ...     776\n",
              "31            47.0  ...     776\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJS_XGK-0O4m"
      },
      "source": [
        "It looks like those cases are errors and not articles, so let's drop them and look again at the description of the max_len column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9X3Y9uc0cgM"
      },
      "source": [
        "new_df = df[df['max_len'] > 776].copy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "RX0vYNjW0iHn",
        "outputId": "da3c2930-1f46-4c48-f56c-f1a4d938d7d5"
      },
      "source": [
        "new_df.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Number</th>\n",
              "      <th>len_content_1</th>\n",
              "      <th>len_content_2</th>\n",
              "      <th>max_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>67.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>67.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>289.761194</td>\n",
              "      <td>4860.313433</td>\n",
              "      <td>279.746269</td>\n",
              "      <td>4904.044776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>149.121985</td>\n",
              "      <td>5285.676715</td>\n",
              "      <td>747.117092</td>\n",
              "      <td>5261.869470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>589.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>831.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>143.500000</td>\n",
              "      <td>1740.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1776.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>3456.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3519.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>404.500000</td>\n",
              "      <td>4764.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4764.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>587.000000</td>\n",
              "      <td>34310.000000</td>\n",
              "      <td>3519.000000</td>\n",
              "      <td>34310.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Article Number  len_content_1  len_content_2       max_len\n",
              "count       67.000000      67.000000      67.000000     67.000000\n",
              "mean       289.761194    4860.313433     279.746269   4904.044776\n",
              "std        149.121985    5285.676715     747.117092   5261.869470\n",
              "min         70.000000     589.000000       0.000000    831.000000\n",
              "25%        143.500000    1740.500000       0.000000   1776.000000\n",
              "50%        303.000000    3456.000000       0.000000   3519.000000\n",
              "75%        404.500000    4764.000000       0.000000   4764.000000\n",
              "max        587.000000   34310.000000    3519.000000  34310.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtb8Yq-K-4W"
      },
      "source": [
        "Now it looks more reasonable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cruvzyL7KTSi"
      },
      "source": [
        "Last check to make sure it is okay:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LdIPq3RjJ8wt",
        "outputId": "a7079d74-072e-4cfe-d52f-b24d4aae539f"
      },
      "source": [
        "df[df.max_len == 831]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article Number</th>\n",
              "      <th>URL of article</th>\n",
              "      <th>Fake or Satire?</th>\n",
              "      <th>URL of rebutting article</th>\n",
              "      <th>Fake or Satire?.1</th>\n",
              "      <th>content_1</th>\n",
              "      <th>content_2</th>\n",
              "      <th>joined_content_1</th>\n",
              "      <th>joined_content_2</th>\n",
              "      <th>len_content_1</th>\n",
              "      <th>len_content_2</th>\n",
              "      <th>max_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>381.0</td>\n",
              "      <td>http://www.react365.com/59c06b7b050bf/no-more-...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>http://www.snopes.com/no-child-support-2017/</td>\n",
              "      <td>Fake</td>\n",
              "      <td>[ Sunday 21 February    379046 Shares, Donald ...</td>\n",
              "      <td>[ Report Abuse]</td>\n",
              "      <td>Sunday 21 February    379046 Shares Donald tru...</td>\n",
              "      <td>Report Abuse</td>\n",
              "      <td>831</td>\n",
              "      <td>12</td>\n",
              "      <td>831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Article Number  ... max_len\n",
              "197           381.0  ...     831\n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "063MulfgKZPQ"
      },
      "source": [
        "Good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8iKOKw0PrjZ"
      },
      "source": [
        "Let's assume the longest text contains the relevent text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hGfzyCePqhV"
      },
      "source": [
        "new_df['content'] = [new_df.joined_content_1.iloc[i] if (len(new_df.joined_content_1.iloc[i]) > len(new_df.joined_content_2.iloc[i])) else new_df.joined_content_2.iloc[i] for i in range(len(new_df))]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNvIUQd3Nis0"
      },
      "source": [
        "Printing some examples of the contents:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksV3iwekLbWT",
        "outputId": "6b03cf2e-cbb0-481b-9861-4bbe6d55b628"
      },
      "source": [
        "new_df.content[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47    You are here:  \\n\\n\\nby\\n\\n\\nHow Africa\\n\\n\\nA...\n",
              "48    Johnston Wilson McGill, 34, was pronounced dea...\n",
              "66    The whispers are growing louder that President...\n",
              "67    Of all the voices crusading against the so-cal...\n",
              "76    INI World Report > Uncategorized > Proof that ...\n",
              "Name: content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3picQT4kNpsH"
      },
      "source": [
        "We can see the text is dirty.\r\n",
        "\r\n",
        "We need to clean it - remove spaces as \"\\n\", \"\\t\" and unnecessary characters.\r\n",
        "\r\n",
        "Otherwise, it may worsen the results of the model -> garbage in garbage out! \r\n",
        "\r\n",
        "For now, I'll leave it aside because I don't have time, but it is **necessary** step to do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq5GR3-sPgLF"
      },
      "source": [
        "### **Preparing the content for using it in the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxzUTMPVSFuj"
      },
      "source": [
        "First, let's split the data into train set and test set (80/20):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPbWK5Z-R72C"
      },
      "source": [
        "train, test = train_test_split(new_df.content, train_size = 0.8, random_state = 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r17GYjYHxEGe",
        "outputId": "b084e9b9-a750-4af0-8c4a-89cfa67a34c5"
      },
      "source": [
        "print(train.shape)\r\n",
        "print(test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(53,)\n",
            "(14,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGth6AVQB3v7"
      },
      "source": [
        "Our dataset is very small and not enough for good results, but let's move on and continue with what we've got.\r\n",
        "\r\n",
        "The reason for that is most of the articles with the fake news were deleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uMz2wLvNXzm"
      },
      "source": [
        "Let's add tags at the beginning and at the ending of the content and replace many spaces with one space.\r\n",
        "\r\n",
        "And in addition combine all of the articles into one long string, as the model needs to receive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vZVbsFdw1c"
      },
      "source": [
        "def preparing_data(dataset):\r\n",
        "  data = \"\"\r\n",
        "  if type(dataset) == str:\r\n",
        "    dataset = [dataset]\r\n",
        "  for c in dataset:\r\n",
        "      c = re.sub(r\"\\s\", \" \", c) \r\n",
        "      bos_token = '<s>'\r\n",
        "      eos_token = '</s>'\r\n",
        "      data += bos_token + ' ' + c + ' ' + eos_token + '\\n'\r\n",
        "  return data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX0PNymfCfYP"
      },
      "source": [
        "\"s\" notifies the model about the start and \"/s\" about the end of the article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLCnPIwBC3MD"
      },
      "source": [
        "Let's prepare the train and test datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeHjiRP5Tj7R"
      },
      "source": [
        "test_data = preparing_data(test)\r\n",
        "train_data = preparing_data(train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzRrH6AeYbwG"
      },
      "source": [
        "### **Fine Tuning GPT2 model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12uAI-ozZNam"
      },
      "source": [
        "Adding special tokens:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nExx1h0W-enK"
      },
      "source": [
        "We need to introduce to the model our \"s\" tags so it won't consider them as words.\r\n",
        "\r\n",
        "Moreover, we need to add tokens as \"unk\" for unknown words - words (or sub-words) the model doesn't recognize, \"pad\" for padding, and \"mask\" for masking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "7f2ce44f582049beb64199c67365ea4b",
            "6b404a71d95f47958c70cd23d74e8d5b",
            "2d44a3d67b6a4c3bb15a8d866990a5fc",
            "b7e69874a0f64bf4af3cb127cf5762d8",
            "e13eb3c98e0c4ecbb5ec5f0768bd457d",
            "c98571b9fa764b228bff69d30b08a3da",
            "93b41b0c1aaf4d4abbea8ceedbf7f9b5",
            "5069f21dfb47443a827caf42bdfb1fc2",
            "b58b4773a0424e89affac7996910961d",
            "c8ded735256f44219e6978d68828fefa",
            "90432e05d43e4acbbff4d97262f4bb8b",
            "36237e05a707434b8793a2508a5262de",
            "62551e9551e747f4b82c8b6ad7578792",
            "1f83b8acb05e4031adfd29dcf8d06379",
            "30a5a09c8f434e0d928b79dee8b87371",
            "0d64682b44d84fb682e5ae7a946805cc"
          ]
        },
        "id": "FxP4Oady4k9H",
        "outputId": "42a37c36-7a5b-48e1-a593-cc32e668444b"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\r\n",
        "tokenizer.add_special_tokens({\r\n",
        "  \"eos_token\": \"</s>\",\r\n",
        "  \"bos_token\": \"<s>\",\r\n",
        "  \"unk_token\": \"<unk>\",\r\n",
        "  \"pad_token\": \"<pad>\",\r\n",
        "  \"mask_token\": \"<mask>\"\r\n",
        "})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f2ce44f582049beb64199c67365ea4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b58b4773a0424e89affac7996910961d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZrvkpMo4xb4"
      },
      "source": [
        "Configuration - setting vocabulary size (as defined in the pre-trained tokenizer) and setting the id of the \"s\" tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zush4jMR4w-v"
      },
      "source": [
        "config = GPT2Config(\r\n",
        "  vocab_size=tokenizer.vocab_size,\r\n",
        "  bos_token_id=tokenizer.bos_token_id,\r\n",
        "  eos_token_id=tokenizer.eos_token_id,\r\n",
        "  )"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsXpItPHGVlX"
      },
      "source": [
        "Creating the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhT2Och43gL"
      },
      "source": [
        "model = TFGPT2LMHeadModel(config)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjJ6viJLJrqo"
      },
      "source": [
        "Adjusting the token embeddings to the length of the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YcTunOC6Kok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05523804-6904-4745-ba48-a871874eafdb"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.modeling_tf_utils.TFSharedEmbeddings at 0x7fc861792c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "797uaJGei-aa"
      },
      "source": [
        "Passing our texts to the tokenizer (converting the words into id numbers, so we can send them to the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebw_uMuQw1TC"
      },
      "source": [
        "train_encodings = tokenizer.encode(train_data, truncation=True, padding=True)\r\n",
        "test_encodings = tokenizer.encode(test_data, truncation=True, padding=True) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJaxRE9Yy82V",
        "outputId": "94f48c10-15bd-43a2-e764-877686f69004"
      },
      "source": [
        "print(len(train_encodings))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59RkvKUyKfWt"
      },
      "source": [
        "Here we are creating the input to the model, we give the model a vector of ids as input and another vector of ids as output, but with a slide of 1 element.\r\n",
        "\r\n",
        " *Example:*\r\n",
        "\r\n",
        "input = [12, 100, 150, 16]\r\n",
        "\r\n",
        "output = [100, 150, 16, 785]\r\n",
        "\r\n",
        "In that way we train the model to predict (or generate) the next word (or token id)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diYcjcd5MJk6"
      },
      "source": [
        "examples = []\r\n",
        "block_size = 85\r\n",
        "BATCH_SIZE = 12\r\n",
        "BUFFER_SIZE = 1000\r\n",
        "for i in range(0, len(train_encodings) - block_size + 1, block_size):\r\n",
        "  examples.append(train_encodings[i:i + block_size])\r\n",
        "inputs, labels = [], []\r\n",
        "for ex in examples:\r\n",
        "  inputs.append(ex[:-1])\r\n",
        "  labels.append(ex[1:])\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\r\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC0_WEneK8R3",
        "outputId": "4e362a09-887a-42bb-fbc8-dafe6387f13b"
      },
      "source": [
        "print(inputs)\r\n",
        "print(labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50258, 4723, 1649, 7183, 717, 1908, 428, 284, 514, 356, 1807, 11, 645, 835, 11, 407, 772, 2486, 561, 307, 428, 1099, 1203, 13, 887, 356, 547, 2642, 13, 8732, 2486, 11764, 1444, 319, 5293, 16269, 284, 3015, 287, 3431, 447, 247, 82, 3071, 13, 770, 2187, 3662, 318, 1099, 1203, 0, 1119, 6486, 379, 790, 1210, 13, 1119, 19837, 284, 651, 12439, 3804, 13, 1119, 19837, 546, 22497, 13, 1119, 19837, 546, 5073, 447, 247, 82, 2839, 4382, 290, 7237, 13, 39711, 532], [4477, 2174, 843, 783, 484, 389, 4585, 319, 5293, 16269, 284, 3015, 13, 383, 2008, 2058, 422, 19931, 9390, 13, 220, 220, 921, 1276, 307, 18832, 287, 284, 1281, 257, 2912, 13, 39711, 220, 39099, 25, 34108, 30646, 309, 2228, 284, 3497, 257, 22244, 2080, 1301, 851, 887, 679, 13590, 2332, 5588, 220, 7232, 557, 3442, 3961, 5926, 1874, 570, 82, 2293, 1004, 4335, 7623, 286, 833, 2140, 28231, 1114, 16168, 278, 20357, 284, 4946, 220, 18321, 3101, 6288, 25, 5617, 3078, 5345, 284], [10127, 1301, 46226, 39826, 35536, 287, 9589, 11, 7859, 290, 7055, 1680, 24889, 39711, 15251, 383, 29916, 350, 917, 270, 35798, 5865, 510, 329, 674, 1479, 3053, 13129, 11, 290, 356, 1183, 787, 1654, 284, 1394, 345, 287, 262, 9052, 13, 220, 39711, 39711, 10673, 12131, 383, 29916, 350, 917, 270, 784, 1439, 6923, 33876, 13, 39711, 39711, 50257, 50258, 18165, 338, 911, 715, 6386, 13362, 3000, 8090, 220, 42953, 309, 36048, 851, 2080, 465, 3278, 3146, 1871, 2042, 4446, 33627, 1088, 352, 7441], [6796, 10429, 3759, 1301, 7478, 22499, 14549, 290, 19912, 3000, 18920, 520, 25415, 16189, 355, 465, 564, 250, 32863, 305, 3806, 16250, 6118, 447, 251, 20656, 13, 564, 250, 3347, 20417, 351, 326, 1448, 11, 447, 251, 531, 1301, 11, 564, 250, 392, 673, 447, 247, 297, 307, 23754, 13, 7731, 345, 766, 607, 379, 262, 46485, 30, 1375, 373, 23754, 355, 262, 29980, 3806, 16250, 5890, 11, 523, 356, 3181, 607, 319, 3096, 13, 775, 447, 247, 260, 9670, 284, 423, 607, 13], [447, 247, 82, 8381, 11, 475, 673, 447, 247, 82, 530, 286, 262, 922, 3392, 13, 447, 251, 16189, 2904, 2727, 10386, 416, 4585, 13980, 447, 247, 82, 28880, 9145, 8674, 18033, 6484, 257, 564, 250, 15060, 341, 11778, 447, 251, 706, 465, 38651, 15434, 4046, 4585, 329, 281, 886, 284, 10713, 290, 644, 339, 1444, 564, 250, 30844, 34503, 13, 447, 251, 1301, 531, 783, 517, 621, 1683, 11, 564, 250, 16480, 351, 564, 246, 35403, 6545, 5073, 447, 247, 44105, 12484, 572], [15102, 11, 447, 251, 9137, 23424, 318, 262, 3580, 1022, 5442, 290, 6078, 287, 3389, 13, 564, 250, 1639, 760, 644, 481, 1645, 11, 447, 251, 531, 1301, 13, 564, 250, 464, 2056, 481, 1282, 866, 319, 502, 329, 2282, 564, 246, 1820, 15102, 13, 447, 247, 1119, 750, 326, 287, 3442, 351, 326, 5510, 12, 7437, 5891, 287, 262, 4315, 11, 475, 345, 760, 644, 30, 314, 836, 447, 247, 83, 447, 247, 1337, 13, 520, 25415, 481, 3031, 284, 477, 262, 2628], [761, 284, 3151, 13, 447, 251, 1881, 286, 883, 2628, 318, 262, 10637, 2055, 11, 4586, 2795, 11, 262, 1012, 38835, 14549, 447, 247, 3651, 546, 12436, 779, 416, 10637, 3925, 2727, 16968, 10386, 13, 16189, 531, 661, 508, 564, 250, 5171, 447, 247, 83, 5409, 644, 484, 18869, 307, 326, 1110, 447, 251, 815, 467, 284, 262, 12436, 564, 250, 259, 262, 37413, 13, 447, 251, 26406, 910, 1301, 447, 247, 82, 1413, 743, 772, 307, 39822, 16189, 329, 7927, 1893, 13, 1406], [11, 1301, 447, 247, 82, 1790, 1351, 3407, 968, 8221, 10964, 13, 5180, 16929, 11, 290, 1966, 2097, 14931, 290, 4787, 4540, 40893, 29855, 13, 564, 250, 3347, 447, 247, 82, 845, 880, 12, 35698, 13, 1375, 447, 247, 82, 2407, 5676, 13, 775, 447, 247, 303, 587, 2045, 656, 340, 11, 447, 251, 531, 1301, 13, 1649, 1965, 611, 262, 3381, 564, 250, 32863, 305, 447, 251, 373, 257, 1774, 3381, 284, 779, 287, 1584, 11, 257, 1301, 6523, 531, 11, 564, 250], [5876, 351, 2282, 564, 246, 43032, 12, 7437, 447, 247, 318, 326, 407, 477, 15102, 389, 422, 5478, 11, 290, 617, 286, 606, 3588, 447, 247, 83, 772, 3399, 13, 2773, 286, 606, 389, 422, 5694, 2253, 11, 290, 772, 15295, 16707, 13, 447, 251, 564, 250, 2514, 307, 19889, 11, 356, 3066, 1028, 564, 246, 25717, 11, 447, 247, 1201, 262, 39829, 991, 3544, 326, 13, 775, 531, 645, 284, 564, 246, 13424, 11, 447, 247, 780, 326, 14846, 1165, 13559, 2890, 13], [262, 886, 11, 356, 1816, 351, 564, 246, 12480, 305, 13, 447, 247, 632, 447, 247, 82, 15074, 7187, 13, 10528, 9811, 546, 340, 13, 447, 251, 564, 250, 3673, 2279, 318, 546, 3234, 11, 447, 251, 2087, 262, 6523, 13, 564, 250, 1135, 2911, 520, 25415, 16189, 481, 787, 326, 1109, 1598, 284, 345, 661, 1752, 290, 329, 477, 13, 447, 251, 35717, 25, 32468, 1503, 2640, 32, 17682, 5626, 30936, 13315, 3563, 11598, 56, 360, 11211, 357, 5159, 8090, 25, 1610, 1134], [8, 314, 373, 3555, 262, 584, 1110, 326, 5519, 389, 2282, 326, 1201, 2279, 1625, 503, 286, 5478, 326, 2042, 2125, 447, 247, 83, 1107, 257, 3234, 290, 326, 340, 447, 247, 82, 1223, 2073, 475, 484, 447, 247, 260, 407, 1654, 644, 13, 1406, 314, 4724, 314, 4236, 351, 3759, 1301, 447, 247, 82, 3572, 13, 3894, 262, 43172, 1422, 447, 247, 83, 869, 2405, 2330, 1566, 706, 484, 1625, 284, 2258, 2253, 475, 611, 345, 765, 284, 307, 1444, 2330, 788, 326], [3734, 13, 1002, 262, 2619, 582, 4702, 284, 15494, 355, 2619, 788, 326, 815, 307, 3734, 1165, 13, 632, 447, 247, 82, 407, 510, 284, 345, 11, 1301, 393, 645, 530, 2073, 284, 1560, 2619, 7974, 508, 484, 389, 393, 508, 345, 765, 606, 284, 307, 13, 4042, 27875, 655, 765, 284, 307, 2619, 13, 1892, 5510, 1605, 11, 407, 27115, 393, 1997, 2073, 13, 2329, 2619, 611, 340, 447, 247, 82, 12876, 351, 21349, 447, 247, 297, 13, 2449, 15977, 13, 5338, 287]]\n",
            "[[4723, 1649, 7183, 717, 1908, 428, 284, 514, 356, 1807, 11, 645, 835, 11, 407, 772, 2486, 561, 307, 428, 1099, 1203, 13, 887, 356, 547, 2642, 13, 8732, 2486, 11764, 1444, 319, 5293, 16269, 284, 3015, 287, 3431, 447, 247, 82, 3071, 13, 770, 2187, 3662, 318, 1099, 1203, 0, 1119, 6486, 379, 790, 1210, 13, 1119, 19837, 284, 651, 12439, 3804, 13, 1119, 19837, 546, 22497, 13, 1119, 19837, 546, 5073, 447, 247, 82, 2839, 4382, 290, 7237, 13, 39711, 532, 1621], [2174, 843, 783, 484, 389, 4585, 319, 5293, 16269, 284, 3015, 13, 383, 2008, 2058, 422, 19931, 9390, 13, 220, 220, 921, 1276, 307, 18832, 287, 284, 1281, 257, 2912, 13, 39711, 220, 39099, 25, 34108, 30646, 309, 2228, 284, 3497, 257, 22244, 2080, 1301, 851, 887, 679, 13590, 2332, 5588, 220, 7232, 557, 3442, 3961, 5926, 1874, 570, 82, 2293, 1004, 4335, 7623, 286, 833, 2140, 28231, 1114, 16168, 278, 20357, 284, 4946, 220, 18321, 3101, 6288, 25, 5617, 3078, 5345, 284, 12642], [1301, 46226, 39826, 35536, 287, 9589, 11, 7859, 290, 7055, 1680, 24889, 39711, 15251, 383, 29916, 350, 917, 270, 35798, 5865, 510, 329, 674, 1479, 3053, 13129, 11, 290, 356, 1183, 787, 1654, 284, 1394, 345, 287, 262, 9052, 13, 220, 39711, 39711, 10673, 12131, 383, 29916, 350, 917, 270, 784, 1439, 6923, 33876, 13, 39711, 39711, 50257, 50258, 18165, 338, 911, 715, 6386, 13362, 3000, 8090, 220, 42953, 309, 36048, 851, 2080, 465, 3278, 3146, 1871, 2042, 4446, 33627, 1088, 352, 7441, 39715], [10429, 3759, 1301, 7478, 22499, 14549, 290, 19912, 3000, 18920, 520, 25415, 16189, 355, 465, 564, 250, 32863, 305, 3806, 16250, 6118, 447, 251, 20656, 13, 564, 250, 3347, 20417, 351, 326, 1448, 11, 447, 251, 531, 1301, 11, 564, 250, 392, 673, 447, 247, 297, 307, 23754, 13, 7731, 345, 766, 607, 379, 262, 46485, 30, 1375, 373, 23754, 355, 262, 29980, 3806, 16250, 5890, 11, 523, 356, 3181, 607, 319, 3096, 13, 775, 447, 247, 260, 9670, 284, 423, 607, 13, 1375], [247, 82, 8381, 11, 475, 673, 447, 247, 82, 530, 286, 262, 922, 3392, 13, 447, 251, 16189, 2904, 2727, 10386, 416, 4585, 13980, 447, 247, 82, 28880, 9145, 8674, 18033, 6484, 257, 564, 250, 15060, 341, 11778, 447, 251, 706, 465, 38651, 15434, 4046, 4585, 329, 281, 886, 284, 10713, 290, 644, 339, 1444, 564, 250, 30844, 34503, 13, 447, 251, 1301, 531, 783, 517, 621, 1683, 11, 564, 250, 16480, 351, 564, 246, 35403, 6545, 5073, 447, 247, 44105, 12484, 572, 616], [11, 447, 251, 9137, 23424, 318, 262, 3580, 1022, 5442, 290, 6078, 287, 3389, 13, 564, 250, 1639, 760, 644, 481, 1645, 11, 447, 251, 531, 1301, 13, 564, 250, 464, 2056, 481, 1282, 866, 319, 502, 329, 2282, 564, 246, 1820, 15102, 13, 447, 247, 1119, 750, 326, 287, 3442, 351, 326, 5510, 12, 7437, 5891, 287, 262, 4315, 11, 475, 345, 760, 644, 30, 314, 836, 447, 247, 83, 447, 247, 1337, 13, 520, 25415, 481, 3031, 284, 477, 262, 2628, 356], [284, 3151, 13, 447, 251, 1881, 286, 883, 2628, 318, 262, 10637, 2055, 11, 4586, 2795, 11, 262, 1012, 38835, 14549, 447, 247, 3651, 546, 12436, 779, 416, 10637, 3925, 2727, 16968, 10386, 13, 16189, 531, 661, 508, 564, 250, 5171, 447, 247, 83, 5409, 644, 484, 18869, 307, 326, 1110, 447, 251, 815, 467, 284, 262, 12436, 564, 250, 259, 262, 37413, 13, 447, 251, 26406, 910, 1301, 447, 247, 82, 1413, 743, 772, 307, 39822, 16189, 329, 7927, 1893, 13, 1406, 1290], [1301, 447, 247, 82, 1790, 1351, 3407, 968, 8221, 10964, 13, 5180, 16929, 11, 290, 1966, 2097, 14931, 290, 4787, 4540, 40893, 29855, 13, 564, 250, 3347, 447, 247, 82, 845, 880, 12, 35698, 13, 1375, 447, 247, 82, 2407, 5676, 13, 775, 447, 247, 303, 587, 2045, 656, 340, 11, 447, 251, 531, 1301, 13, 1649, 1965, 611, 262, 3381, 564, 250, 32863, 305, 447, 251, 373, 257, 1774, 3381, 284, 779, 287, 1584, 11, 257, 1301, 6523, 531, 11, 564, 250, 464], [351, 2282, 564, 246, 43032, 12, 7437, 447, 247, 318, 326, 407, 477, 15102, 389, 422, 5478, 11, 290, 617, 286, 606, 3588, 447, 247, 83, 772, 3399, 13, 2773, 286, 606, 389, 422, 5694, 2253, 11, 290, 772, 15295, 16707, 13, 447, 251, 564, 250, 2514, 307, 19889, 11, 356, 3066, 1028, 564, 246, 25717, 11, 447, 247, 1201, 262, 39829, 991, 3544, 326, 13, 775, 531, 645, 284, 564, 246, 13424, 11, 447, 247, 780, 326, 14846, 1165, 13559, 2890, 13, 554], [886, 11, 356, 1816, 351, 564, 246, 12480, 305, 13, 447, 247, 632, 447, 247, 82, 15074, 7187, 13, 10528, 9811, 546, 340, 13, 447, 251, 564, 250, 3673, 2279, 318, 546, 3234, 11, 447, 251, 2087, 262, 6523, 13, 564, 250, 1135, 2911, 520, 25415, 16189, 481, 787, 326, 1109, 1598, 284, 345, 661, 1752, 290, 329, 477, 13, 447, 251, 35717, 25, 32468, 1503, 2640, 32, 17682, 5626, 30936, 13315, 3563, 11598, 56, 360, 11211, 357, 5159, 8090, 25, 1610, 1134, 81], [314, 373, 3555, 262, 584, 1110, 326, 5519, 389, 2282, 326, 1201, 2279, 1625, 503, 286, 5478, 326, 2042, 2125, 447, 247, 83, 1107, 257, 3234, 290, 326, 340, 447, 247, 82, 1223, 2073, 475, 484, 447, 247, 260, 407, 1654, 644, 13, 1406, 314, 4724, 314, 4236, 351, 3759, 1301, 447, 247, 82, 3572, 13, 3894, 262, 43172, 1422, 447, 247, 83, 869, 2405, 2330, 1566, 706, 484, 1625, 284, 2258, 2253, 475, 611, 345, 765, 284, 307, 1444, 2330, 788, 326, 318], [13, 1002, 262, 2619, 582, 4702, 284, 15494, 355, 2619, 788, 326, 815, 307, 3734, 1165, 13, 632, 447, 247, 82, 407, 510, 284, 345, 11, 1301, 393, 645, 530, 2073, 284, 1560, 2619, 7974, 508, 484, 389, 393, 508, 345, 765, 606, 284, 307, 13, 4042, 27875, 655, 765, 284, 307, 2619, 13, 1892, 5510, 1605, 11, 407, 27115, 393, 1997, 2073, 13, 2329, 2619, 611, 340, 447, 247, 82, 12876, 351, 21349, 447, 247, 297, 13, 2449, 15977, 13, 5338, 287, 12379]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz2l4ys5MY2S"
      },
      "source": [
        "Defining optimizer, loss function, and metric to evaluate the model and eventually compiling the model with what we've defined:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ttqS_JMJWK"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, epsilon=0.0001, clipnorm=1.0)\r\n",
        "\r\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "\r\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, loss=[loss, *[None] * model.config.n_layer], metrics=[metric])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPzY0vM_MzHu"
      },
      "source": [
        "Fitting the model with the trainset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVVxF9xMJAE",
        "outputId": "fef13a9e-c3b0-4e42-b09f-c3deb3fc1c9f"
      },
      "source": [
        "num_epoch = 10\r\n",
        "history = model.fit(dataset, epochs=num_epoch)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc8f3de1bb0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc8f3de1bb0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc90f18f0e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fc90f18f0e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1/1 [==============================] - 47s 47s/step - loss: 10.9682 - logits_loss: 10.9682 - logits_accuracy: 0.0000e+00 - past_key_values_1_accuracy: 0.0016 - past_key_values_2_accuracy: 0.0011 - past_key_values_3_accuracy: 0.0016 - past_key_values_4_accuracy: 9.0939e-04 - past_key_values_5_accuracy: 0.0026 - past_key_values_6_accuracy: 8.6806e-04 - past_key_values_7_accuracy: 5.3737e-04 - past_key_values_8_accuracy: 9.0939e-04 - past_key_values_9_accuracy: 0.0013 - past_key_values_10_accuracy: 0.0013 - past_key_values_11_accuracy: 0.0017 - past_key_values_12_accuracy: 0.0012\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 327ms/step - loss: 10.0281 - logits_loss: 10.0281 - logits_accuracy: 0.0466 - past_key_values_1_accuracy: 0.0013 - past_key_values_2_accuracy: 8.2672e-05 - past_key_values_3_accuracy: 0.0031 - past_key_values_4_accuracy: 6.6138e-04 - past_key_values_5_accuracy: 3.7202e-04 - past_key_values_6_accuracy: 0.0026 - past_key_values_7_accuracy: 5.3737e-04 - past_key_values_8_accuracy: 0.0014 - past_key_values_9_accuracy: 0.0015 - past_key_values_10_accuracy: 1.2401e-04 - past_key_values_11_accuracy: 9.5073e-04 - past_key_values_12_accuracy: 0.0028\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 332ms/step - loss: 11.7532 - logits_loss: 11.7532 - logits_accuracy: 0.0188 - past_key_values_1_accuracy: 7.4405e-04 - past_key_values_2_accuracy: 9.9206e-04 - past_key_values_3_accuracy: 1.2401e-04 - past_key_values_4_accuracy: 9.9206e-04 - past_key_values_5_accuracy: 7.8538e-04 - past_key_values_6_accuracy: 0.0026 - past_key_values_7_accuracy: 0.0012 - past_key_values_8_accuracy: 0.0012 - past_key_values_9_accuracy: 0.0012 - past_key_values_10_accuracy: 0.0041 - past_key_values_11_accuracy: 0.0026 - past_key_values_12_accuracy: 0.0020\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 8.5654 - logits_loss: 8.5654 - logits_accuracy: 0.0466 - past_key_values_1_accuracy: 0.0011 - past_key_values_2_accuracy: 1.2401e-04 - past_key_values_3_accuracy: 0.0042 - past_key_values_4_accuracy: 5.7870e-04 - past_key_values_5_accuracy: 0.0015 - past_key_values_6_accuracy: 0.0021 - past_key_values_7_accuracy: 5.7870e-04 - past_key_values_8_accuracy: 0.0026 - past_key_values_9_accuracy: 0.0019 - past_key_values_10_accuracy: 2.8935e-04 - past_key_values_11_accuracy: 9.9206e-04 - past_key_values_12_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 320ms/step - loss: 7.8299 - logits_loss: 7.8299 - logits_accuracy: 0.0268 - past_key_values_1_accuracy: 0.0011 - past_key_values_2_accuracy: 0.0000e+00 - past_key_values_3_accuracy: 0.0021 - past_key_values_4_accuracy: 7.0271e-04 - past_key_values_5_accuracy: 8.2672e-05 - past_key_values_6_accuracy: 9.9206e-04 - past_key_values_7_accuracy: 2.0668e-04 - past_key_values_8_accuracy: 0.0020 - past_key_values_9_accuracy: 0.0018 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 0.0025 - past_key_values_12_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 7.1718 - logits_loss: 7.1718 - logits_accuracy: 0.0139 - past_key_values_1_accuracy: 9.0939e-04 - past_key_values_2_accuracy: 0.0000e+00 - past_key_values_3_accuracy: 0.0020 - past_key_values_4_accuracy: 3.3069e-04 - past_key_values_5_accuracy: 4.1336e-05 - past_key_values_6_accuracy: 0.0035 - past_key_values_7_accuracy: 6.6138e-04 - past_key_values_8_accuracy: 0.0021 - past_key_values_9_accuracy: 9.9206e-04 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 9.9206e-04 - past_key_values_12_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 324ms/step - loss: 7.0046 - logits_loss: 7.0046 - logits_accuracy: 0.0069 - past_key_values_1_accuracy: 9.0939e-04 - past_key_values_2_accuracy: 4.1336e-05 - past_key_values_3_accuracy: 0.0013 - past_key_values_4_accuracy: 3.3069e-04 - past_key_values_5_accuracy: 4.1336e-05 - past_key_values_6_accuracy: 0.0014 - past_key_values_7_accuracy: 1.2401e-04 - past_key_values_8_accuracy: 0.0016 - past_key_values_9_accuracy: 8.6806e-04 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 9.9206e-04 - past_key_values_12_accuracy: 9.9206e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 6.6747 - logits_loss: 6.6747 - logits_accuracy: 0.0486 - past_key_values_1_accuracy: 4.5470e-04 - past_key_values_2_accuracy: 0.0000e+00 - past_key_values_3_accuracy: 0.0029 - past_key_values_4_accuracy: 3.7202e-04 - past_key_values_5_accuracy: 0.0000e+00 - past_key_values_6_accuracy: 1.6534e-04 - past_key_values_7_accuracy: 4.5470e-04 - past_key_values_8_accuracy: 0.0022 - past_key_values_9_accuracy: 0.0014 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 0.0000e+00 - past_key_values_12_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 319ms/step - loss: 6.2459 - logits_loss: 6.2459 - logits_accuracy: 0.0337 - past_key_values_1_accuracy: 0.0014 - past_key_values_2_accuracy: 0.0000e+00 - past_key_values_3_accuracy: 0.0036 - past_key_values_4_accuracy: 0.0012 - past_key_values_5_accuracy: 4.1336e-05 - past_key_values_6_accuracy: 0.0016 - past_key_values_7_accuracy: 6.6138e-04 - past_key_values_8_accuracy: 0.0032 - past_key_values_9_accuracy: 9.9206e-04 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 5.7870e-04 - past_key_values_12_accuracy: 0.0017\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 326ms/step - loss: 5.9335 - logits_loss: 5.9335 - logits_accuracy: 0.0466 - past_key_values_1_accuracy: 8.6806e-04 - past_key_values_2_accuracy: 2.0668e-04 - past_key_values_3_accuracy: 0.0016 - past_key_values_4_accuracy: 7.8538e-04 - past_key_values_5_accuracy: 4.9603e-04 - past_key_values_6_accuracy: 0.0011 - past_key_values_7_accuracy: 0.0018 - past_key_values_8_accuracy: 0.0022 - past_key_values_9_accuracy: 0.0000e+00 - past_key_values_10_accuracy: 4.9603e-04 - past_key_values_11_accuracy: 0.0025 - past_key_values_12_accuracy: 4.9603e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USR28WkeNV3K"
      },
      "source": [
        "Evaluating the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JABWGpY3MnrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2de7f6-b3ab-49cf-ebf2-403f47995f88"
      },
      "source": [
        "model.evaluate(test_encodings)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "32/32 [==============================] - 2s 4ms/step - loss: 0.0000e+00 - logits_loss: 0.0000e+00 - logits_accuracy: 0.0000e+00 - past_key_values_1_accuracy: 0.0000e+00 - past_key_values_2_accuracy: 0.0000e+00 - past_key_values_3_accuracy: 0.0000e+00 - past_key_values_4_accuracy: 0.0000e+00 - past_key_values_5_accuracy: 0.0000e+00 - past_key_values_6_accuracy: 0.0000e+00 - past_key_values_7_accuracy: 0.0000e+00 - past_key_values_8_accuracy: 0.0000e+00 - past_key_values_9_accuracy: 0.0000e+00 - past_key_values_10_accuracy: 0.0000e+00 - past_key_values_11_accuracy: 0.0000e+00 - past_key_values_12_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnURe0hMQ9wL"
      },
      "source": [
        "The model needs to be trained on more examples, for improvement of the performances.\r\n",
        "\r\n",
        "Here we can see that the accuracy of the model equal to zero, which means, the model guesses the next word to generate (bad model).\r\n",
        "\r\n",
        "I think accuracy isn't a good metric to evaluate the model, I think we should calculate the perplexity of the model (exp of the loss).\r\n",
        "perplexity is a measurement of how well a probability distribution or probability model predicts a sample. A low perplexity indicates the probability distribution is good at predicting the sample.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXPkuiQOSfFO"
      },
      "source": [
        "**Using the model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCDcRZOdXVwA"
      },
      "source": [
        "In the deployment the user will submit a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTJKcGnFUVyM"
      },
      "source": [
        "sentence = 'Hi how are you?'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RutL4dW1XbVW"
      },
      "source": [
        "In the background the sentence will be tokenized and then the model will generate text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK_NVYUZUcIO",
        "outputId": "1c885c5d-949d-4bcf-af28-86d01636d947"
      },
      "source": [
        "input_ids = tokenizer.encode(sentence, truncation=True, padding=True, return_tensors='tf')\r\n",
        "beam_output = model.generate(\r\n",
        "  input_ids,\r\n",
        "  max_length = 50,\r\n",
        "  num_beams = 5,\r\n",
        "  temperature = 0.7,\r\n",
        "  no_repeat_ngram_size=2,\r\n",
        "  num_return_sequences=5\r\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50257 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V62TY3zT-Qx"
      },
      "source": [
        "Translating back the predicted tokens into words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEOKy8LJHcRi",
        "outputId": "1256c4b4-40af-4c72-ec4a-65578770d889"
      },
      "source": [
        "print(tokenizer.decode(beam_output[0]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi how are you?�� �� to”� that“�, to to � � to� to that to� to,� the�.’� and� Trump�s� transgender� with� Donald� one\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A9SvMHbTSfj"
      },
      "source": [
        "As we can see, the results don't make sense respectively to the low performances of the model."
      ]
    }
  ]
}